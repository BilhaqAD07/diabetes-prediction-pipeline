{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIABETES PREDICTION\n",
    "\n",
    "### Created by : BilhaqAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from modules.pipeline import init_local_pipeline\n",
    "from modules.components import init_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET VARIABEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"crossnexx-pipeline\"\n",
    "\n",
    "# Pipeline inputs root\n",
    "DATA_ROOT = \"data\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
    "TUNER_MODULE_FILE = \"modules/tuner.py\"\n",
    "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
    "\n",
    "# Pipeline outputs root\n",
    "OUTPUT_BASE = \"outputs\"\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN PIPELINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 03m 11s]\n",
      "binary_accuracy: 0.9623562693595886\n",
      "\n",
      "Best binary_accuracy So Far: 0.9623562693595886\n",
      "Total elapsed time: 00h 13m 37s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in outputs\\crossnexx-pipeline\\Tuner\\.system\\executor_execution\\7\\.temp\\7\\kt_randomsearch\n",
      "Showing 10 best trials\n",
      "Objective(name=\"binary_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "dense_unit: 144\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.9623562693595886\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 1\n",
      "dense_unit: 176\n",
      "dropout_rate: 0.6\n",
      "learning_rate: 0.001\n",
      "Score: 0.9608937501907349\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "dense_unit: 80\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.01\n",
      "Score: 0.9578062295913696\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "dense_unit: 176\n",
      "dropout_rate: 0.9\n",
      "learning_rate: 0.01\n",
      "Score: 0.9151406288146973\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 2\n",
      "dense_unit: 48\n",
      "dropout_rate: 0.9\n",
      "learning_rate: 0.001\n",
      "Score: 0.9132187366485596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " gender_xf (InputLayer)         [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " smoking_history_xf (InputLayer  [(None, 4)]         0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " age_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " hypertension_xf (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " heart_disease_xf (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " bmi_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " HbA1c_level_xf (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " blood_glucose_level_xf (InputL  [(None, 1)]         0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 13)           0           ['gender_xf[0][0]',              \n",
      "                                                                  'smoking_history_xf[0][0]',     \n",
      "                                                                  'age_xf[0][0]',                 \n",
      "                                                                  'hypertension_xf[0][0]',        \n",
      "                                                                  'heart_disease_xf[0][0]',       \n",
      "                                                                  'bmi_xf[0][0]',                 \n",
      "                                                                  'HbA1c_level_xf[0][0]',         \n",
      "                                                                  'blood_glucose_level_xf[0][0]'] \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 144)          2016        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 144)          20880       ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 144)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 144)          20880       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 144)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 144)          20880       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 144)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            145         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64,801\n",
      "Trainable params: 64,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "5000/5000 [==============================] - ETA: 0s - loss: 0.1088 - binary_accuracy: 0.9624\n",
      "Epoch 1: val_binary_accuracy improved from -inf to 0.95714, saving model to outputs\\crossnexx-pipeline\\Trainer\\model\\8\\Format-Serving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) HbA1c_level_xf with unsupported characters which will be renamed to hba1c_level_xf in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\crossnexx-pipeline\\Trainer\\model\\8\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\crossnexx-pipeline\\Trainer\\model\\8\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 225s 44ms/step - loss: 0.1088 - binary_accuracy: 0.9624 - val_loss: 0.1051 - val_binary_accuracy: 0.9571\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\crossnexx-pipeline\\Trainer\\model\\8\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\crossnexx-pipeline\\Trainer\\model\\8\\Format-Serving\\assets\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['----direct_num_workers=0']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000289DF6C9D60> and <keras.engine.input_layer.InputLayer object at 0x00000289DF6D0DC0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000289DF6C9D60> and <keras.engine.input_layer.InputLayer object at 0x00000289DF6D0DC0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000289E0F19EE0> and <keras.engine.input_layer.InputLayer object at 0x00000289E0F0F580>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000289E0F19EE0> and <keras.engine.input_layer.InputLayer object at 0x00000289E0F0F580>).\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['----direct_num_workers=0']\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714754945   nanos: 52036523 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714754945   nanos: 98770618 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714754987   nanos: 866865396 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000223263F0250> and <keras.engine.input_layer.InputLayer object at 0x0000022326785A60>).\" instruction_id: \"bundle_464\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714754994   nanos: 490026950 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000022329DB8790> and <keras.engine.input_layer.InputLayer object at 0x0000022329D9D400>).\" instruction_id: \"bundle_464\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714754996   nanos: 10284185 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_464\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714755085   nanos: 807083845 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002232F7BC9D0> and <keras.engine.input_layer.InputLayer object at 0x000002232F7CF910>).\" instruction_id: \"bundle_470\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714755093   nanos: 59596776 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002232645AD90> and <keras.engine.input_layer.InputLayer object at 0x000002232F9D6400>).\" instruction_id: \"bundle_470\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714755100   nanos: 520631790 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002232C6E34C0> and <keras.engine.input_layer.InputLayer object at 0x000002232C6457C0>).\" instruction_id: \"bundle_473\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714755110   nanos: 920685529 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000223362784F0> and <keras.engine.input_layer.InputLayer object at 0x000002233625A190>).\" instruction_id: \"bundle_476\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1714755122   nanos: 673790216 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002233772FF10> and <keras.engine.input_layer.InputLayer object at 0x00000223376D1130>).\" instruction_id: \"bundle_476\" log_location: \"C:\\\\Users\\\\bilha\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    }
   ],
   "source": [
    "components = init_components(\n",
    "    data_dir=DATA_ROOT,\n",
    "    transform_module=TRANSFORM_MODULE_FILE,\n",
    "    tuner_module=TUNER_MODULE_FILE,\n",
    "    training_module=TRAINER_MODULE_FILE,\n",
    "    train_steps=5000,\n",
    "    eval_steps=1000,\n",
    "    serving_model_dir=serving_model_dir\n",
    ")\n",
    "\n",
    "pipeline = init_local_pipeline(components, pipeline_root)\n",
    "\n",
    "BeamDagRunner().run(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subs_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
